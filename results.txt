TRAIN DATA:
label
neutral     22177
positive    19563
negative     7713
Name: count, dtype: int64

Examples:
          label                                              tweet
4569   negative  This is starting to feel like less like a pett...
760    positive  That movie Flight with Denzel looks really goo...
16700   neutral  SAD asks Rahul Gandhi what action he has taken...


TEST DATA:
label
neutral     5743
negative    3811
positive    2352
Name: count, dtype: int64

Examples:
          label                                              tweet
10590  positive  Fans can find Base Series 2 in The Armory pack...
7198    neutral  The latest The Omeopatia-Homeopathy Weekly! ht...
7426    neutral  Chinese Web Sites are censuring "Kim Fatty the...


Labels:
{0: "negative", 1: "neutral", 2:"positive"}

RESULTS:

RATIO: (original)
label
1    22177
2    19563
0     7713

classification report:
              precision    recall  f1-score   support

           0       0.69      0.70      0.70      3811
           1       0.70      0.69      0.70      5743
           2       0.67      0.68      0.67      2352

    accuracy                           0.69     11906
   macro avg       0.69      0.69      0.69     11906
weighted avg       0.69      0.69      0.69     11906

confusion matrix:
[[2675 1004  132]
 [1098 3986  659]
 [  78  682 1592]]


RATIO:
label
1    22177
0    19563
2     7713

classification report:
              precision    recall  f1-score   support

           0       0.61      0.86      0.71      3811
           1       0.71      0.62      0.66      5743
           2       0.80      0.49      0.61      2352

    accuracy                           0.67     11906
   macro avg       0.71      0.66      0.66     11906
weighted avg       0.69      0.67      0.67     11906

confusion matrix:
[[3288  485   38]
 [1918 3578  247]
 [ 198  991 1163]]


RATIO:
label
2    26505
1    22177
0      771

classification report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00      3811
           1       0.54      0.84      0.66      5743
           2       0.60      0.74      0.66      2352

    accuracy                           0.55     11906
   macro avg       0.38      0.53      0.44     11906
weighted avg       0.38      0.55      0.45     11906

confusion matrix:
[[   0 3567  244]
 [   0 4841  902]
 [   0  615 1737]]


RATIO:
label
0    26505
1    22177
2      771

classification report:
              precision    recall  f1-score   support
           0       0.59      0.87      0.70      3811
           1       0.59      0.64      0.62      5743
           2       1.00      0.01      0.03      2352

    accuracy                           0.59     11906
   macro avg       0.73      0.51      0.45     11906
weighted avg       0.67      0.59      0.53     11906

confusion matrix:
[[3334  477    0]
 [2067 3676    0]
 [ 278 2039   35]]
 
 
 RATIO:
label
2    27199
1    22177
0       77

classification report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00      3811
           1       0.54      0.83      0.65      5743
           2       0.58      0.75      0.66      2352

    accuracy                           0.55     11906
   macro avg       0.37      0.53      0.44     11906
weighted avg       0.38      0.55      0.45     11906

confusion matrix:
[[   0 3514  297]
 [   0 4781  962]
 [   0  581 1771]]


RATIO:
label
0    27199
1    22177
2       77

classification report:
              precision    recall  f1-score   support

           0       0.58      0.89      0.70      3811
           1       0.60      0.63      0.61      5743
           2       0.00      0.00      0.00      2352

    accuracy                           0.59     11906
   macro avg       0.39      0.50      0.44     11906
weighted avg       0.47      0.59      0.52     11906

confusion matrix:
[[3377  434    0]
 [2133 3610    0]
 [ 330 2022    0]]



RATIO:
label
1    22177
0    15426
2    11850

classification report:
              precision    recall  f1-score   support

           0       0.64      0.82      0.72      3811
           1       0.72      0.65      0.68      5743
           2       0.75      0.58      0.65      2352

    accuracy                           0.69     11906
   macro avg       0.70      0.68      0.68     11906
weighted avg       0.70      0.69      0.69     11906

confusion matrix:
[[3138  607   66]
 [1642 3708  393]
 [ 137  850 1365]]