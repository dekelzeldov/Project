{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "from datasets import Dataset\n",
    "from datasets import DatasetDict\n",
    "from datasets import concatenate_datasets\n",
    "from datasets import load_metric\n",
    "from datasets import Features\n",
    "from datasets import Value\n",
    "from datasets import ClassLabel\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from transformers import pipeline\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          label                                              tweet\n",
      "902    positive  Huh, Kofi Annan tomorrow. Look at you, @maddow...\n",
      "10744   neutral  Gucci plenty she fair prospect march fall out ...\n",
      "14676   neutral  Tom Brady Speaks for the 1st Time Since Suspen...\n",
      "          label                                              tweet\n",
      "10143   neutral  KC preparing for self-driving cars https://t.c...\n",
      "4767    neutral                   @HuffingtonPost Some Bad Hombres\n",
      "233    positive  #GilmoreGirlsTop4 Lane, Luke, Paris and Sookie...\n"
     ]
    }
   ],
   "source": [
    "### Data to pandas\n",
    "\n",
    "# labels to ids\n",
    "id2label = {0: \"negative\", 1: \"neutral\", 2:\"positive\"}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "# fuction to creat dataset from file\n",
    "def pandas_from_file(filename):\n",
    "    # print(\"\\n\\n************ \"+filename)\n",
    "    data = pandas.read_table(filename, delimiter=\"\\t\", names=[\"label\", \"tweet\"], usecols=[1,2])\n",
    "    # print(data.sample(n=3))\n",
    "    return data\n",
    "\n",
    "# training data\n",
    "directory = 'semeval-2017-tweets_Subtask-A/downloaded/'\n",
    "training_dataframes = []\n",
    "for filename in os.listdir(directory):\n",
    "    training_dataframes.append(pandas_from_file(directory+filename))\n",
    "\n",
    "# mearge\n",
    "training_merged = pandas.concat(training_dataframes).drop_duplicates()\n",
    "\n",
    "# test data\n",
    "testing_dataframe = pandas_from_file(\"SemEval2017-task4-test.subtask-A.english.txt\")\n",
    "\n",
    "# sanity checks\n",
    "assert(training_merged.notna().values.all())\n",
    "assert(training_merged[\"label\"].isin(label2id.keys()).all())\n",
    "print(training_merged.sample(n=3))\n",
    "print(testing_dataframe.sample(n=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## crate dict with all rations\n",
    "\n",
    "\n",
    "# # start dict with the training data\n",
    "# ratiod_dataframes = [training_merged]\n",
    "\n",
    "# # rebalnce based on geven rations and add to dict\n",
    "# no_neutral = training_merged[training_merged[\"label\"] != \"neutral\"]\n",
    "# neutrals = training_merged[training_merged[\"label\"] == \"neutral\"]\n",
    "\n",
    "neg_count = training_merged[training_merged[\"label\"] == \"negative\"].shape[0]\n",
    "neut_count = training_merged[training_merged[\"label\"] == \"neutral\"].shape[0]\n",
    "pos_count = training_merged[training_merged[\"label\"] == \"positive\"].shape[0]\n",
    "total = neg_count + pos_count\n",
    "\n",
    "# ratios = [pos_count, int(0.1*neg_count), total-int(0.1*neg_count), int(0.01*neg_count), total-int(0.01*neg_count) , 2*neg_count]\n",
    "# for negs in ratios:\n",
    "#     print({\"negative\": negs, \"positive\": total-negs})\n",
    "#     print(no_neutral[\"tweet\"])\n",
    "#     print(no_neutral[\"label\"])\n",
    "#     smote = SMOTE(sampling_strategy={\"negative\": negs, \"positive\": total-negs})\n",
    "#     resampled = smote.fit_resample(no_neutral[\"tweet\"], no_neutral[\"label\"])\n",
    "#     # ratiod_dataframes.append(pandas.concat([resampled, neutrals]))\n",
    "\n",
    "# # # sanity\n",
    "# # for df in ratiod_dataframes.items():\n",
    "# #     print(df['label'].value_counts()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pandas to dataset\n",
    "\n",
    "# dataset features\n",
    "features = Features({'tweet': Value('string'), 'label': ClassLabel(names=list(label2id.keys()))})\n",
    "\n",
    "# create the dataset\n",
    "train_dataset = Dataset.from_pandas(training_merged.replace({\"labels\": label2id}), preserve_index=False, features=features)\n",
    "test_dataset = Dataset.from_pandas(testing_dataframe.replace({\"labels\": label2id}), preserve_index=False, features=features)\n",
    "\n",
    "dataset = DatasetDict({\"train\": train_dataset, \"validation\":test_dataset})\n",
    "\n",
    "# ratiod_datasets = {}\n",
    "# for (ratio , training_pand) in ratiod_dataframes.items(): \n",
    "#     # convert pandas to dataset\n",
    "#     train_dataset = Dataset.from_pandas(training_pand.replace({\"labels\": label2id}), preserve_index=False, features=features)\n",
    "#     test_dataset = Dataset.from_pandas(testing_dataframe.replace({\"labels\": label2id}), preserve_index=False, features=features)\n",
    "\n",
    "#     # create the dataset\n",
    "#     dataset = DatasetDict({\"train\": train_dataset, \"validation\":test_dataset})\n",
    "\n",
    "#     # add to dict\n",
    "#     ratiod_datasets[ratio] = dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Metrics\n",
    "# define metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    \n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    metrics = [\"precision\", \"recall\", \"f1\"]\n",
    "    results = {m : load_metric(m).compute(predictions=predictions, references=labels, average=\"micro\")[m] for m in metrics}\n",
    "    results[\"accuracy\"] = load_metric(\"accuracy\").compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fa6e46bd824a7ba67ad6a62e80cc8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d59ab4cb9b4ffaa4bbe0efa0fb793f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11906 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 36\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tokenized_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# data collector\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorWithPadding(tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m## Trainer\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# FIXME change loss function?\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# training args\u001b[39;00m\n\u001b[1;32m     42\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     43\u001b[0m output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinetuning\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     44\u001b[0m per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m )\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Model and Training\n",
    "\n",
    "negs = [0, pos_count, int(0.1*neg_count), total-int(0.1*neg_count), int(0.01*neg_count), total-int(0.01*neg_count) , 2*neg_count]\n",
    "\n",
    "for n in negs:  \n",
    "\n",
    "    ## Model and Tokenizer\n",
    "\n",
    "    # load pretraind modle and tokenizer from checkpoint\n",
    "    model_checkpoint = \"distilbert-base-uncased\"\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3, \n",
    "        id2label=id2label,\n",
    "        label2id=label2id)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "    ## Tokinization\n",
    "\n",
    "    # tokenize the data\n",
    "    tokenized_datasets = dataset.map(\n",
    "        (lambda tweet: tokenizer(tweet[\"tweet\"] , truncation=True, padding=True)), \n",
    "        batched=True\n",
    "        )\n",
    "\n",
    "    if (n != 0):\n",
    "        print(tokenized_datasets[\"train\"])\n",
    "\n",
    "        smote = SMOTE(sampling_strategy={0: n, 1:neut_count, 2: total-n})\n",
    "        smoted_train = smote.fit_resample(tokenized_datasets[\"train\"][\"tweet\"], tokenized_datasets[\"train\"][\"label\"])\n",
    "        tokenized_datasets = Dataset.from_pandas(smoted_train)\n",
    "        \n",
    "        print(tokenized_datasets[\"train\"])\n",
    "\n",
    "    \n",
    "\n",
    "    # data collector\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    ## Trainer\n",
    "\n",
    "    # FIXME change loss function?\n",
    "    # training args\n",
    "    training_args = TrainingArguments(\n",
    "    output_dir=\"finetuning\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=6e-6,\n",
    "    evaluation_strategy=\"epoch\"\n",
    "    )\n",
    "\n",
    "    # initialize trainer \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    ## Train and Eval\n",
    "    trainer.train()\n",
    "    trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
